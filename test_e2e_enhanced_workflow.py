#!/usr/bin/env python3
"""
End-to-End Enhanced Workflow Test
=================================
Test the complete workflow using the Enhanced Test Creation Agent
to ensure it generates real code instead of templates.
"""

import asyncio
import json
import logging
import os
from datetime import datetime
from pathlib import Path

# Setup logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# Import components
from complete_orchestrator import CompleteOrchestrator
from parsers.unified_parser import UnifiedTestFileParser

class EnhancedWorkflowTester:
    """Test the complete workflow with Enhanced Test Creation Agent"""
    
    def __init__(self):
        self.orchestrator = CompleteOrchestrator()
        self.parser = UnifiedTestFileParser()
        
    async def test_enhanced_e2e_workflow(self):
        """Test complete end-to-end workflow with Enhanced Agent"""
        
        logger.info("ğŸš€ Starting Enhanced E2E Workflow Test")
        
        try:
            # Initialize orchestrator
            await self.orchestrator.initialize()
            logger.info("âœ… Orchestrator initialized")
            
            # Create a simple test scenario
            test_scenario = """
Scenario: Enhanced Login Test
Description: Test user login functionality with Enhanced Agent
Steps:
1. Navigate to login page
2. Enter username: testuser
3. Enter password: testpass
4. Click login button
5. Verify successful login
Expected: User should be logged in successfully
"""
            
            # Save scenario to file
            scenario_file = "enhanced_test_scenario.txt"
            with open(scenario_file, 'w') as f:
                f.write(test_scenario)
            
            logger.info("ğŸ“ Created test scenario file")
            
            # Parse the scenario
            parsed_result = self.parser.parse_file(scenario_file)
            logger.info(f"âœ… Parsed scenario: {len(parsed_result.scenarios)} scenarios found")
            
            # Run the complete workflow
            logger.info("ğŸ”„ Running complete workflow with Enhanced Agent")
            
            # Create a temporary scenario file for the workflow
            temp_scenario_file = Path(scenario_file).absolute()
            
            workflow_result = await self.orchestrator.execute_complete_workflow(
                input_files=[str(temp_scenario_file)]
            )
            
            logger.info(f"âœ… Workflow completed: {workflow_result.get('success', False)}")
            
            # Analyze the generated code
            await self.analyze_generated_code()
            
            # Verify Enhanced Agent was used
            await self.verify_enhanced_agent_usage()
            
            return workflow_result
            
        except Exception as e:
            logger.error(f"âŒ Enhanced E2E workflow test failed: {str(e)}")
            return {"success": False, "error": str(e)}
    
    async def analyze_generated_code(self):
        """Analyze the generated code to verify it's real code, not templates"""
        
        logger.info("ğŸ” Analyzing generated code quality")
        
        # Check Enhanced Test Creation Agent output directory
        enhanced_dir = Path("work_dir/EnhancedTestCreationAgent")
        if enhanced_dir.exists():
            logger.info(f"âœ… Enhanced Agent directory found: {enhanced_dir}")
            
            # Check for generated files
            generated_files = list(enhanced_dir.glob("*.py"))
            logger.info(f"ğŸ“„ Found {len(generated_files)} Python files")
            
            real_code_count = 0
            template_count = 0
            
            for file_path in generated_files:
                with open(file_path, 'r') as f:
                    content = f.read()
                
                # Check for template indicators
                has_templates = "{{" in content and "}}" in content
                has_real_selectors = any(selector in content for selector in [
                    "#loginBtn", "#username", "#password", ".welcome-message"
                ])
                has_assertions = any(assertion in content for assertion in [
                    "assert", "expect(", "should", "toBe"
                ])
                
                if has_templates:
                    template_count += 1
                    logger.warning(f"âš ï¸ Template found in: {file_path.name}")
                else:
                    real_code_count += 1
                    logger.info(f"âœ… Real code in: {file_path.name}")
                
                logger.info(f"   ğŸ“Š {file_path.name}: Selectors={has_real_selectors}, Assertions={has_assertions}, Templates={has_templates}")
            
            # Summary
            total_files = len(generated_files)
            if total_files > 0:
                real_code_percentage = (real_code_count / total_files) * 100
                logger.info(f"ğŸ“Š Code Quality Summary:")
                logger.info(f"   Total files: {total_files}")
                logger.info(f"   Real code files: {real_code_count}")
                logger.info(f"   Template files: {template_count}")
                logger.info(f"   Real code percentage: {real_code_percentage:.1f}%")
                
                if real_code_percentage >= 90:
                    logger.info("ğŸ‰ EXCELLENT: Enhanced Agent generating real code!")
                elif real_code_percentage >= 70:
                    logger.info("âœ… GOOD: Mostly real code with some templates")
                else:
                    logger.warning("âš ï¸ ISSUE: Too many templates, Enhanced Agent not working properly")
            else:
                logger.warning("âš ï¸ No Python files generated")
        else:
            logger.warning("âš ï¸ Enhanced Agent directory not found")
    
    async def verify_enhanced_agent_usage(self):
        """Verify that the Enhanced Test Creation Agent was actually used"""
        
        logger.info("ğŸ” Verifying Enhanced Agent usage")
        
        # Check if Enhanced Agent was initialized
        test_creation_agent = self.orchestrator.agents.get("test_creation")
        
        if test_creation_agent:
            agent_class = test_creation_agent.__class__.__name__
            logger.info(f"ğŸ“‹ Test Creation Agent class: {agent_class}")
            
            if "Enhanced" in agent_class:
                logger.info("âœ… Enhanced Test Creation Agent is being used")
                
                # Check capabilities
                capabilities = test_creation_agent.get_capabilities()
                enhanced_capabilities = [
                    "real_code_generation",
                    "discovery_integration",
                    "page_object_models"
                ]
                
                has_enhanced_caps = all(cap in capabilities for cap in enhanced_capabilities)
                
                if has_enhanced_caps:
                    logger.info("âœ… Enhanced capabilities confirmed")
                else:
                    logger.warning("âš ï¸ Enhanced capabilities not found")
            else:
                logger.error("âŒ Original Test Creation Agent is still being used!")
        else:
            logger.error("âŒ No Test Creation Agent found in orchestrator")
    
    async def run_comparison_test(self):
        """Run a comparison between original and enhanced workflows"""
        
        logger.info("ğŸ”„ Running comparison test")
        
        # This would compare the old vs new agent outputs
        # For now, we'll just verify the Enhanced Agent is working
        
        result = await self.test_enhanced_e2e_workflow()
        
        if result.get("success"):
            logger.info("ğŸ‰ Enhanced workflow test PASSED")
        else:
            logger.error("âŒ Enhanced workflow test FAILED")
        
        return result

async def main():
    """Main test function"""
    
    print("\n" + "="*70)
    print("ENHANCED END-TO-END WORKFLOW TEST")
    print("="*70)
    
    tester = EnhancedWorkflowTester()
    
    try:
        # Run the enhanced workflow test
        result = await tester.run_comparison_test()
        
        if result.get("success"):
            print("\nğŸ‰ SUCCESS: Enhanced E2E workflow is working!")
            print("âœ… Enhanced Test Creation Agent integrated successfully")
            print("âœ… Real code generation confirmed")
            print("âœ… Complete workflow functional")
        else:
            print("\nâŒ FAILURE: Enhanced E2E workflow has issues")
            print("âš ï¸ Check logs above for specific problems")
            print("ğŸ”§ May need to debug orchestrator integration")
        
        return result.get("success", False)
        
    except Exception as e:
        print(f"\nâŒ CRITICAL ERROR: {str(e)}")
        logger.error(f"Critical error in main: {str(e)}")
        return False

if __name__ == "__main__":
    success = asyncio.run(main())
    exit(0 if success else 1)

